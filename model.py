# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X-LaAJ9KcUybA7KFpWbk19yjWtwfZKCd
"""

#importing Libraries
import tensorflow as tf
import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.optimizers import Adam

# ==== CONFIGURATION ====
import kagglehub

# Download latest version
DATASET_PATH = kagglehub.dataset_download("maxwellkuria/animals-that-destroy-farms-in-kenya")

#DATASET_PATH = '/kaggle/input/animals-that-destroy-farms-in-kenya/DataSet'
IMG_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 20

VALIDATION_SPLIT = 0.2

# === ImageDataGenerator with validation split ===
train_val_gen = ImageDataGenerator(
    rescale=1./255,
    validation_split=VALIDATION_SPLIT,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

# === Training set from 80% of the data ===
train_data = train_val_gen.flow_from_directory(
      os.path.join(DATASET_PATH, "DataSet"),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',   # Only use training part
    shuffle=True,
    seed=42
)

# === Validation set from 20% of the data ===
val_data = train_val_gen.flow_from_directory(
     os.path.join(DATASET_PATH, "DataSet"),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',  # Only use validation part
    shuffle=True,
    seed=42
)

NUM_CLASSES = len(train_data.class_indices)

print(train_data.class_indices)

# ==== BUILD MODEL ====
base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(NUM_CLASSES, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

optimizer = Adam(learning_rate=0.0001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# ==== CALLBACKS ====
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
checkpoint = ModelCheckpoint('/kaggle/working/best_model.h5', save_best_only=True, monitor='val_loss')

# ==== TRAIN MODEL ====
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=EPOCHS,
    callbacks=[early_stop, checkpoint]
)

# ========== Evaluation: Classification Report, Confusion Matrix, ROC ==========
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.preprocessing import label_binarize
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Get true labels
val_data.reset()
y_true = val_data.classes  # actual class index (0, 1, 2, ...)

# 2. Get predicted probabilities and classes
y_pred_probs = model.predict(val_data, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)

# 3. Classification report
class_labels = list(val_data.class_indices.keys())
print("Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_labels))

# 4. Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.savefig('/kaggle/working/confusion_matrix.png')
plt.show()

# 5. ROC Curve (multi-class)
y_true_bin = label_binarize(y_true, classes=np.arange(len(class_labels)))

fpr = {}
tpr = {}
roc_auc = {}

for i in range(len(class_labels)):
    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot ROC Curves
plt.figure(figsize=(10, 7))
for i in range(len(class_labels)):
    plt.plot(fpr[i], tpr[i], label=f'{class_labels[i]} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (Multi-class)")
plt.legend()
plt.grid()
plt.savefig('/kaggle/working/roc_curve.png')
plt.show()

# ==== PLOT ACCURACY & LOSS ====
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title("Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title("Loss")
plt.legend()
plt.show()

model.save("best_model.h5")   # saves in HDF5 format

from google.colab import files
files.download("best_model.h5")

import tensorflow as tf

# Load the trained .h5 model
model = tf.keras.models.load_model("best_model.h5")

# Convert to TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save locally in Colab
with open("best_model.tflite", "wb") as f:
    f.write(tflite_model)

from google.colab import files
files.download("best_model.tflite")